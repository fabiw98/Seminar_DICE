\chapter{Theoretische Grundlagen}

In diesem Kapitel werden zunächst wichtige Begriffe aus dem Bereich der erklärbaren KI vorgestellt und in dem Kontext von DiCE erläutert.

\section{Grundlegende Begriffe}
% ML-Modell
Ein \textit{Modell des maschinellen Lernens} (ML-Modell) ist ein algorithmisches System, das mit Trainingsdaten zur Erkennung von Mustern durch überwachtes, unüberwachtes, halbüberwachtes oder bestärkendes Lernen trainiert wurde. Anschließend kann das Modell unbekannte Eingabedaten auf Basis des gelernten Wissens verarbeiten und klassifizieren.

% Input: Feature Vector
Die Eingabe erfolgt als ein sogenannter \textit{Feature Vector}, wobei die Dimension gleich der Anzahl an kategorischen und numerischen Merkmalen ist.
% Output: Klasse
Das Ergebnis erfolgt über die Angabe einer \textit{Klasse}, zu der eine Eingabe durch das ML-Modell zugeordnet wurde.
% Original Input / Output? Eigentlich selbsterklärend
Die \textit{ursprüngliche Eingabe} bezeichnet den unveränderten Feature Vector, welcher in einer \textit{ungewollten Klasse} resultiert. 
% CF
Ein \textit{Counterfactual} (CF) ist hingegen eine leicht veränderte Eingabe. Das CF wird so gewählt, dass nicht die ursprünglich erhaltene, ungewollte Klasse das Ergebnis ist, sondern eine sogenannte \textit{CF Klasse}.

% CF Klasse


% Black-Box vs. White-Box-Modelle


% Lokale vs. Globale Erklärungsansätze



\section{Definition von DiCE}
% DiCE: post-hoc, black-box, lokaler Ansatz
\textbf{Di}verse \textbf{C}ounterfactual \textbf{E}xplanations ist ein Erklärungsansatz, um Entscheidungen von ML-Modellen für den Menschen verständlich zu machen. Es handelt sich um ein lokales, post-hoc Verfahren für Black-Box-Modelle. Die Erklärung des Modells findet somit nach der Trainingsphase statt und dient der Bewertung, Nachvollziehbarkeit sowie dem Aufzeigen von Schwächen oder einem Bias des Modells.

% Problem
% Ist das nicht in der Einleitung schon beschrieben oder muss das nochmal hier hin?

% Ansatz zum Lösen des Problems
