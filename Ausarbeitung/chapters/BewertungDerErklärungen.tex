\chapter{Evaluation der Methodik}

In diesem Kapitel werden zunächst die Evaluationsmetriken für Gültigkeit, Proximität, Diversität und Sparsität definiert, um generierte Erklärungen bewerten zu können. Anschließend werden die Metriken bewertet und das Konzept der sogenannten Entscheidungsgrenze als das angestrebte Ziel betrachtet.


\section{Evaluationsmetriken}
%- Validity
Die Gültigkeitsmetrik in Gleichung \ref{validity} beschreibt den Anteil $\%ValidCFs$ an eindeutigen Counterfactuals aus der Menge $C$ aller generierten Erklärungen, wobei $k$ die Anzahl an geforderten CFs ist. Gültigkeit ist ein wichtiges Maß, da DiCE nicht auf die Einzigartigkeit der Erklärungen prüft.\cite{mothilal2020dice}
\begin{equation}\label{validity}
	\%ValidCFs = \frac{|\{\text{unique instance in } C \text{s.t. } f(c)>0.5\}|}{k}
\end{equation}

%- Proximity
Die Proximitätsmetrik bewertet, wie nah die Counterfactuals $c_i$ an der ursprünglichen Eingabe $x$ im Feature-Raum sind. Die kontinuierlichen und kategorialen Features werden getrennt evaluiert.
In Gleichung \ref{proximity_contc} werden zunächst die Distanzen $dist\_cont$ der kontinuierlichen Features der einzelnen Counterfactuals im Bezug auf die ursprüngliche Eingabe berechnet. Anschließend wird der Mittelwert dieser Distanzen über alle $k$ generierten Counterfactuals gebildet. Abschließend wird der Wert negativ dargestellt, um die Metrik von der Distanz in einen Proximitätswert umzuwandeln, sodass eine kleine Distanz in einer großen Nähe resultiert.\cite{mothilal2020dice}
\begin{align}\label{proximity_contc}
	ContinuousProximity &:= - \frac{1}{k} \sum_{i=1}^{k}{dist\_cont(c_i,x)} %\\
					  % &= - \frac{1}{k} \sum_{i=1}^{k}{\left( \frac{1}{d_{cont}}\sum_{p=1}^{d_{cont}}\frac{|c^{p}-x^{p}|}{MAD_{p}} \right)} 
\end{align}
In Gleichung \ref{proximity_cat} wird zunächst die Distanz $dist\_cat$ der kategorialen Features der einzelnen Counterfactuals im Bezug auf die ursprüngliche Eingabe berechnet, welche zählt, wie viele kategoriale Features sich geändert haben. Anschließend wird der Mittelwert der Distanzen über alle $k$ generierten Counterfactuals gebildet. Um den Anteil der kategorialen Features zu repräsentieren, welche nicht geändert wurden, wird in einem letzten Schritt die Distanz von Eins subtrahiert. Eine hohe kategoriale Proximität resultiert somit in einem Wert nahe Eins, da nur wenige kategorialen Features geändert wurden.\cite{mothilal2020dice}
\begin{align}\label{proximity_cat}
	CategoricalProximity &:= 1 - \frac{1}{k} \sum_{i=1}^{k}{dist\_cat(c_i,x)} %\\
						% &= 1 - \frac{1}{k} \sum_{i=1}^{k}{\left( \frac{1}{d_{cat}}\sum_{p=1}^{d_{cat}}I(c^{p}\ne x^{p}) \right)}
\end{align}

%- Sparsity
Sparsität ist eine Metrik, um die Machbarkeit der generierten Erklärungen zu bewerten. Dieser Wert ist für kategoriale Features identisch mit der Proximität. Einfachheitshalber werden kontinuierliche und kategoriale Merkmale in der Sparsität zu einer einzigen Metrik in Gleichung \ref{sparsity_metric} zusammengefasst. Für jedes Counterfactual $c_i$ wird die Anzahl an veränderten Features im Vergleich zur ursprünglichen Eingabe $x$ gezählt. Jedes der $k$ Counterfactuals besitzt $d$ Merkmale. Anschließend wird der Mittelwert über alle Counterfactuals und Features berechnet und von Eins subtrahiert. Ein hoher Sparsitätswert nahe Eins bedeutet, dass nur wenige Features in den Erklärungen verändert wurden und ist für eine Umsetzbarkeit der Erklärungen anzustreben.\cite{mothilal2020dice}
\begin{equation}\label{sparsity_metric}
	Sparsity := 1- \frac{1}{kd} \sum_{i=1}^{k} \sum_{l=1}^{d}{1_{[c_i^l \ne x_i^l]}}
\end{equation}

%- Diversity
Die Diversitätsmetrik wird analog zur Proximität definiert und in kontinuierliche und kategoriale Diversität aufgeteilt, wie in den Gleichungen \ref{diversity_cont_metric} und \ref{diversity_cat_metric} dargestellt ist. Der Unterschied liegt darin, dass nun die Distanz der Features zwischen zwei Counterfactuals $c_i$ und $c_j$ gemessen wird. Die Anzahl aller möglichen CF-Paare ist $C_k^2$. Im Anschluss an die Berechnung der kategorialen und kontinuierlichen Distanz wird jeweils der Mittelwert über die Distanzen gebildet. Ein hoher Wert bedeutet, dass eine große Diversität zwischen den einzelnen Erklärungen vorliegt. Dies resultiert in größeren Unterschieden zwischen den Counterfactuals, wodurch die Umsetzbarkeit für den Anwender wahrscheinlicher wird.
\cite{mothilal2020dice}
\begin{equation}\label{diversity_cont_metric}
	ContinuousDiversity := \Delta = \frac{1}{C_k^2} \sum_{i=1}^{k-1} \sum_{j=i+1}^{k}{dist\_cont(c_i,c_j)}
\end{equation}
\begin{equation}\label{diversity_cat_metric}
	CategoricalDiversity := \Delta = \frac{1}{C_k^2} \sum_{i=1}^{k-1} \sum_{j=i+1}^{k}{dist\_cat(c_i,c_j)}
\end{equation}

%- Count-Diversity
Analog zu der Sparsität kann eine weitere Diversitätsmetrik (Gleichung \ref{count-diversity}) formuliert werden, welche den Durchschnitt aller unterschiedlichen Features beim paarweisen Vergleich der Counterfactuals angibt.
\cite{mothilal2020dice}
\begin{equation}\label{count-diversity}
	CountDiversity := \Delta = \frac{1}{C_k^2d} \sum_{i=1}^{k-1} \sum_{j=i+1}^{k} \sum_{l=1}^{d}{1_{[c_i^l \ne c_j^l]}}
\end{equation}


\section{Bewertung der Evaluationsqualität}
%- Wie aussagekräftig / gut sind die Metriken?
Nachdem im vorherigen Abschnitt die Evaluationsmetriken definiert wurden, muss nun deren Güte überprüft werden. Die Funktion der Metriken ist die Bewertung einer Menge von generierten Erklärungen im Hinblick auf Gültigkeit, Proximität, Sparsität und Diversität.

\subsection{Bewertung der Evaluationsmetriken}
% Gültigkeit
Die Gültigkeitsmetrik stellt sicher, dass die Counterfactuals tatsächlich einzigartige und passende Erklärungen für das vorliegende Problem sind. Eine Erklärung, die nicht korrekt in die gewünschte Zielklasse klassifiziert wird, ist wertlos. Dies gilt auch für mehrfache Generierungen derselben Erklärung, da keine neuen Erkenntnisse gewonnen werden können.\cite{mothilal2020dice}

% Proximität und Sparsität
Um die Nähe zwischen der Eingabe und den Counterfactuals zu bewerten, sind die Proximitäts- und Sparsitätsmetriken notwendig. Sie sind zentraler Bestandteil, um eine Aussage über die Umsetzbarkeit von Erklärungen tätigen zu können. Je näher eine Erklärung an der ursprünglichen Eingabe ist, desto höher ist die Umsetzbarkeit dieser Erklärung in der Praxis. Eine niedrige Proximität zwischen Erklärung und Ursprung führt zum Verlust des Zusammenhangs, wodurch die Erklärungen nutzlos werden. Dies verhindert jedoch nicht, dass alle Features gleichzeitig variiert werden. Aus diesem Grund ist Sparsität als separate Metrik relevant, da sie sicherstellt, dass nur eine minimale Anzahl an Merkmalen verändert wird. Dies garantiert, dass der Anwender nur möglichst wenige Anpassungen vornehmen muss.\cite{mothilal2020dice}

% Diversität
Die bisherigen Metriken stellen sicher, dass die Counterfactuals zwar valide, einzigartig und nahe an der Eingabe sind, vernachlässigen jedoch die Beziehung zwischen den Erklärungen selbst. Die Maximierung der Unterschiede zwischen den Counterfactuals wird durch die Diversität erreicht. Dies erhöht die Wahrscheinlichkeit, dass die CF-Menge eine für den Anwender umsetzbare Erklärung beinhaltet. Damit ist Diversität für den Anwender essentiell, um die Entscheidungsgrenze des ML-Modells besser verstehen zu können. Es ist jedoch zu beachten, dass eine hohe Diversität auf Kosten der Proximität geht, da sie konkurrierende Ziele verfolgen.\cite{mothilal2020dice}


\subsection{Näherung der Entscheidungsgrenze}
% Entscheidungsgrenze
Die Optimierung der besprochenen Metriken ist wünschenswert, doch sie sind nicht das endgültige Ziel. Das Ziel von DiCE ist es, mithilfe von Counterfactuals einem Anwender die lokale Entscheidungsgrenze und Logik von ML-Modellen aufzuzeigen. Dies soll dem Anwender ermöglichen, die Entscheidungen, die ein Modell für ähnliche Eingaben treffen wird, vorherzusagen.
% Präzision (Metrik)
Eine Metrik für eine Messung der Entscheidung, wird über die Verwendung eines weiteren ML-Modells realisiert. Dieses wird auf den generierten Counterfactuals und der ursprünglichen Eingabe trainiert und simuliert einen Anwender. Die Güte der Erklärungen kann daran gemessen werden, wie gut das zweite ML-Modell das ursprüngliche Modell imitieren kann.\cite{mothilal2020dice}


%todo - Wie gut im Vergleich zu anderen Erkkärungsansätzen? => Lasse ich weg, wenn das ok ist





















